<!DOCTYPE html>
<html lang="ko">
<head>
  <link rel="stylesheet" href="style.css">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

  <h1>📁 팀 프로젝트: [문서 이미지 분류]</h1>

  <div class="section">
    <h2>📝 프로젝트 개요</h2>
    <p>금융, 의료, 보험 등 산업 전반의 문서를 이미지 기반으로 분류하는 문서 타입 분류 대회에 참가하여, 다양한 이미지 증강과 앙상블 모델을 활용해 고성능 모델을 개발한 프로젝트입니다.</p>
  </div>

  <div class="section">
    <h2>⏱️ 기간 및 인원</h2>
    <p><span class="highlight">기간:</span> 2025.02.14 ~ 2025.02.25</p>
    <p><span class="highlight">인원:</span> 총 5명</p>
  </div>

  <div class="section">
    <h2>🛠 기술 스택</h2>
    <p><strong>프로그래밍 언어 및 도구:</strong> Python, Jupyter Notebook, Pandas, torchvision, Wandb</p>
    <p><strong>사용 모델:</strong> ResNet50, EfficientNet-B3, YOLOv12</p>
  </div>

  <div class="section">
    <h2>🔧 핵심 기능</h2>
    <ul>
      <li>✔ 이미지 전처리 및 증강(Augraphy, Albumentations)
        <details>
          <summary style="cursor:pointer; color:#0a9396; margin-top:5px;">📊 이미지 보기</summary>
          <figure>
            <img src="../images/03_Document_Type_Classification/EDA1.png" alt="Train/Test 데이터의 클래스 분포를 시각화한 막대그래프" />
            <figcaption>📌 EDA1: train & test data의 target이 어떻게 구성되어 있는지 파악</figcaption>
          </figure>
          <figure>
            <img src="../images/03_Document_Type_Classification/EDA2.png" alt="Train 데이터에서 각 클래스(target)별 이미지 개수 시각화" />
            <figcaption>📌 EDA2: 각 target 별 train data의 개수를 확인</figcaption>
          </figure>
          <figure>
            <img src="../images/03_Document_Type_Classification/augmentation1.png" alt="BindingsAndFasteners 및 Clahe 적용된 문서 이미지" />
            <img src="../images/03_Document_Type_Classification/augmentation2.png" alt="BleedThrough 및 Brightness Texturize 적용된 문서 이미지" />
            <img src="../images/03_Document_Type_Classification/augmentation3.png" alt="Brightness 및 VoronoiTessellation 적용된 문서 이미지" />
            <img src="../images/03_Document_Type_Classification/augmentation4.png" alt="GaussianNoise(gausiannoise) 적용된 문서 이미지" />
            <img src="../images/03_Document_Type_Classification/augmentation_mixup.png" alt="Mixup 적용된 문서 이미지" />
            <figcaption>📌 시도해본 다양한 증강 기법들</figcaption>
          </figure>
        </details>
      </li>
      <li>✔ 다양한 모델 실험 (ResNet50, EfficientNet-B3, SwinTransformer-T)
        <details>
          <summary style="cursor:pointer; color:#0a9396; margin-top:5px;">📊 이미지 보기</summary>
          <figure>
            <img src="../images/03_Document_Type_Classification/model.png" alt="wandb를 이용한 모델별 성능 비교 그래프" />
            <figcaption>📌 wandb를 통한 모델 성능 비교</figcaption>
          </figure>
        </details>      
      </li>
      <li>✔ Sinogram 변환 실험 적용
        <details>
          <summary style="cursor:pointer; color:#0a9396; margin-top:5px;">📊 이미지 보기</summary>
          <figure>
            <img src="../images/03_Document_Type_Classification/sinogram.png" alt="Radon 변환 후 Sinogram 이미지" />
            <figcaption>📌 문서 이미지에 Radon 변환을 적용하여 Sinogram으로 변환한 결과</figcaption>
          </figure>
        </details>
      </li>
      <li>✔ YOLOv8로 타이틀 탐지 실험
        <details>
          <summary style="cursor:pointer; color:#0a9396; margin-top:5px;">📊 이미지 보기</summary>
          <figure>
            <img src="../images/03_Document_Type_Classification/YOLO.png" alt="YOLO를 이용한 객체 탐지" />
            <figcaption>📌 Label Studio를 통해 특정 target의 train data 라벨링 진행</figcaption>
          </figure>
        </details>
      </li>
      <li>✔ Wandb sweep을 통한 하이퍼파라미터 튜닝
        <details>
          <summary style="cursor:pointer; color:#0a9396; margin-top:5px;">📊 이미지 보기</summary>
          <figure>
            <img src="../images/03_Document_Type_Classification/wandbsweep.png" alt="Wandb_sweep" />
            <img src="../images/03_Document_Type_Classification/wandb_sweep.png" alt="Wandb_sweep" />
            <figcaption>📌 wandb_sweep 기능을 이용해서 가장 적절한 파라미터 탐색 및 적용</figcaption>
          </figure>
        </details>
      </li>
      <li>✔ Soft Voting 앙상블 적용</li>
    </ul>
  </div>

  <div class="section">
    <h2>🧑‍💻 내가 기여한 부분</h2>
    <ul>
      <li>✔ EDA 기반 클래스 분포 분석 및 전처리 전략 설계</li>
      <li>✔ 다양한 데이터 증강 실험(Augraphy, Albumentations) 적용</li>
      <li>✔ <strong>Sinogram 변환 실험 주도:</strong>  
        문서 이미지를 Radon 변환하여 sinogram 형태로 바꾸는 실험을 진행했습니다.  
        이 방식은 이미지의 노이즈를 주파수 패턴으로 바꿔 제거 가능하게 하며, 회전 및 이동에 대한 불변성을 기대할 수 있었습니다.  
        일반적인 CNN이 자연 이미지에 최적화되어 있어 sinogram 이미지에 대한 특징 추출이 어렵다는 한계를 확인했고,  
        이를 통해 Radon-domain CNN과 같은 특화된 구조의 필요성을 검토하게 되었습니다.  
        결과적으로 이 시도는 sinogram을 직접 학습에 활용하기보다는 전처리나 특화 구조와 함께 사용하는 것이 효과적이라는 인사이트를 제공했습니다.
      </li>
    </ul>
  </div>

<div class="section">
  <h2>🐛 트러블슈팅</h2>
  <details style="margin-top: 12px;">
      <summary style="cursor: pointer; color: #0a9396;"><strong>✔ 회전된 문서 대응 → sinogram 변환 기반 전처리 실험</strong></summary>
      <div style="margin-top: 10px;">
          <p>
          학부 시절 신경공학 수업에서 CT 영상 재구성과 관련된 내용을 학습하면서, 이미지 처리 기법 중 하나인 <strong>Radon 변환</strong>을 처음 접한 경험이 있었습니다. 당시에는 일반 이미지를 sinogram 형태로 변환하고, 다시 역변환을 통해 원래 형태로 복원하는 코드를 직접 작성하며, Radon 변환이 주파수 기반 정보로 이미지를 표현하고 처리할 수 있다는 특성을 흥미롭게 느꼈습니다.
          </p>
          <p>
          이번 프로젝트에서 test 데이터를 분석하던 중, <strong>문서가 회전된 형태</strong>로 존재하는 경우가 꽤 많다는 점을 발견했습니다. 이때 과거 경험이 떠올랐고, sinogram의 특성상 이미지를 다양한 각도로 회전시키며 정보를 누적해 하나의 함수 형태로 표현한다는 점에 주목했습니다. 따라서 단순히 원본 이미지를 학습하는 것보다, 이를 sinogram 형태로 변환한 후 학습시키면 회전에 대해 더 강인한 특성을 보일 수 있지 않을까 하는 가설을 세우고 실험을 설계했습니다.
          </p>
          <p>
          기대했던 효과는 분명했습니다. 첫째, sinogram은 특정 노이즈를 주파수 패턴으로 변환하여 필터링 가능하게 만들며, 둘째로 회전/이동에 대해 일정한 구조로 변환되기 때문에 학습 안정성과 성능 향상이 기대되었습니다.
          </p>
          <p>
          그러나 실험을 거듭할수록 명확한 한계점도 드러났습니다. 일반적인 CNN은 자연 이미지의 시각적 특징에 최적화되어 있기 때문에, sinogram 형태의 이미지에서는 의미 있는 패턴을 잘 추출하지 못했습니다. 이로 인해 성능이 오히려 떨어지기도 했고, 이미지의 지역성(locality)이 사라지면서 네트워크가 중요한 세부 정보를 인식하지 못하는 문제가 있었습니다.
          </p>
          <p>
          이러한 실험을 통해 얻은 결론은 명확했습니다. sinogram은 학습 데이터로 직접 사용하기보다는, <strong>전처리나 데이터 증강의 한 형태로 활용하는 것이 적합</strong>하며, 만약 이를 학습에 직접 활용하고자 한다면 Radon-domain CNN 등 <strong>도메인 특화된 아키텍처</strong>를 설계해야 한다는 것입니다. 단순한 성능 개선을 넘어서, 실험적 시도와 이론적 배경이 접목된 의미 있는 도전이었다고 생각합니다.
          </p>
      </div>
  </details>

  <details>
      <summary style="cursor: pointer; color: #0a9396;"><strong>✔ 특정 문서에서 높은 오탐률 발생 → YOLOv12 기반 키워드 탐지로 보완</strong></summary>
      <div style="margin-top: 8px;">
          <p>
          이미지 증강을 통해 훈련 데이터를 일정 수준 이상 확보한 이후, 모델 성능 향상의 속도가 급격히 둔화되는 현상이 나타났습니다. 단순히 더 많은 증강 데이터를 추가하는 것이 효과적이지 않다고 판단하여, 다른 접근 방식을 모색하게 되었습니다. 먼저 문서별 오탐률을 분석해본 결과, <strong>입퇴원 확인서, 진단서, 외래_진료확인서, 소견서_진료소견서</strong> 등 일부 문서에서 유독 오탐률이 높다는 사실을 확인할 수 있었습니다.
          </p>
          <p>
          이 문제를 해결하기 위해 모델의 구조나 분류 방식 자체를 되돌아보던 중, 사람이 해당 문서를 분류할 때 주로 <strong>'확인서', '진단서'</strong> 등 특정 키워드를 기준으로 판단한다는 점에 주목하게 되었습니다. 이러한 특징을 모델에 반영하기 위해, 객체 탐지 모델 중 하나인 <strong>YOLOv12</strong>를 도입해 해당 키워드를 직접 인식하고 이를 보조 분류 정보로 활용해보기로 했습니다.
          </p>
          <p>
          기본 분류는 ResNet과 EfficientNet으로 진행하고, 위에서 언급한 특정 문서 유형에 대해서만 YOLOv12를 추가로 적용하여 <strong>이중 분류(앙상블)</strong> 구조를 설계했습니다. 그 결과, 해당 문서들의 분류 정확도가 비약적으로 상승했으며, 전체 성능 역시 <strong>0.8615 → 0.9832</strong>로 크게 향상되는 효과를 거두었습니다.
          </p>
      </div>
  </details>
  
  <details>
    <summary style="cursor:pointer; color:#0a9396; margin-top:5px;">📊 이미지 보기</summary>
    <figure>
      <img src="../images/03_Document_Type_Classification/F1score.png" alt="클래스별 오탐률 분포" />
      <figcaption>📌 클래스별 오탐률을 시각화하여 문제 문서를 식별</figcaption>
    </figure>
    <figure>
      <img src="../images/03_Document_Type_Classification/YOLO.png" alt="YOLOv8로 라벨링한 문서 예시" />
      <figcaption>📌 입퇴원확인서, 진단서 등에서 특정 키워드를 YOLO로 탐지한 라벨링 결과</figcaption>
    </figure>
  </details>
</div>

  <div class="section">
    <h2>🌟 팀 성과</h2>
    <ul>
      <li>최종 리더보드 기준 1위 달성</li>
      <img src="../images/03_Document_Type_Classification/FINAL_Score.png" alt="최종 결과" />
      <li>객체 탐지 모델 기반 타이틀 추론 시도 등 다양한 실험 진행</li>
    </ul>
  </div>

  <div class="section">
    <h2>💡 깨달은 점</h2>
    <p>
      이번 프로젝트를 통해 단순한 모델 성능 향상만큼이나 <strong>도메인 특성에 기반한 데이터 전처리와 문제 정의의 중요성</strong>을 깊이 체감했습니다. 특히 일부 문서 유형은 이미지 증강만으로는 성능 개선이 어려웠고, 문서의 구조적 특징(예: 특정 키워드 위치)을 활용한 Object Detection 방식이 훨씬 효과적이라는 사실을 알게 되었습니다.
    </p>
    <p>
      또한 sinogram 변환과 같은 시도는 기존 CNN 아키텍처에 바로 적용하기에는 어려움이 있지만, <strong>이미지 전처리 과정에서의 가능성</strong>과 함께 다양한 방식의 데이터 표현 방법에 대한 탐색이 성능 향상에 실질적인 도움이 될 수 있음을 배웠습니다.
    </p>
    <p>
      무엇보다 문제를 다양한 각도에서 접근해보고, 실패한 실험도 의미 있는 인사이트로 이어질 수 있다는 점에서 <strong>탐구 과정 자체의 가치</strong>를 다시금 느낄 수 있었습니다.
    </p>
    <p>
      그리고 이번 프로젝트를 통해 <strong>Wandb</strong>를 처음 접해보았는데, 실험 결과를 직관적으로 비교하고 시각화할 수 있는 유용성과 편리함에 크게 놀랐습니다. 앞으로도 하이퍼파라미터 탐색이나 모델 실험 시 자주 활용하게 될 것 같습니다.
    </p>
  </div>


  <div class="section">
    <h2>🔗 참고 링크</h2>
    <ul>
      <li>📁 GitHub 저장소: <a href="https://github.com/KJH121212/03_Document_Type_Classification.git" target="_blank">github.com/KJH121212/02_House_Price_prediction</a></li>
    </ul>
  </div>

</body>
</html>
